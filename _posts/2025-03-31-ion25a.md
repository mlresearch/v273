---
title: Adaptive Knowledge Assessment In Simulated Coding Interviews
abstract: We present a system for simulating student coding interview responses to
  sequential inter-view questions, with the goal of accurately inferring student expertise
  levels. With these simulated students, we explored fixed and adaptive question selection
  policies, where the adaptive policy exploits a knowledge component dependency graph
  to maximize information gain. Our results show that adaptive questioning policies
  show increasing benefits compared to a fixed policy as student expertise levels
  rise, achieving expert assessment F1-scores of 0.4-0.8 for student expertise prediction
  compared to 0.25-0.35 for fixed strategies.
section: Poster
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ion25a
month: 0
tex_title: Adaptive Knowledge Assessment In Simulated Coding Interviews
firstpage: 260
lastpage: 262
page: 260-262
order: 260
cycles: false
bibtex_author: Ion, Michael and Ashana, Sumit and Jiao, Fengquan and Wang, Tianyi
  and Collins-Thompson, Kevyn
author:
- given: Michael
  family: Ion
- given: Sumit
  family: Ashana
- given: Fengquan
  family: Jiao
- given: Tianyi
  family: Wang
- given: Kevyn
  family: Collins-Thompson
date: 2025-03-31
address:
container-title: Proceedings of the Innovation and Responsibility in AI-Supported
  Education Workshop
volume: '273'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 3
  - 31
pdf: https://raw.githubusercontent.com/mlresearch/v273/main/assets/ion25a/ion25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
